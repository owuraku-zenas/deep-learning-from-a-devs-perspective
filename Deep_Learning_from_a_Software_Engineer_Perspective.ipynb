{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6263429",
   "metadata": {},
   "source": [
    "# Deep Learning from a Software Engineer's Perspective\n",
    "This notebook explains the process of building and training a deep learning model with PyTorch. The steps include loading and validating data, creating a neural network, training, and finally making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88332cf2",
   "metadata": {},
   "source": [
    "## Problem Identification\n",
    "The task is to classify images into two categories: 'cat' and 'fish'. We'll start by processing our data and training a neural network to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6563dfe",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "We will load and validate images to ensure there are no corrupted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "\n",
    "# Define transformations for the data\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to 64x64 (width x height)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define the data paths\n",
    "train_data_path = \"./images/train/\"\n",
    "val_data_path = \"./images/val/\"\n",
    "test_data_path = \"./images/test/\"\n",
    "\n",
    "def validate_images(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            try:\n",
    "                img = Image.open(os.path.join(root, file))\n",
    "                img.verify()  # Check if it's a valid image\n",
    "            except (IOError, UnidentifiedImageError):\n",
    "                print(f\"Removing corrupted image: {file}\")\n",
    "                os.remove(os.path.join(root, file))  # Remove corrupted file\n",
    "\n",
    "validate_images(train_data_path)\n",
    "validate_images(val_data_path)\n",
    "validate_images(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db96925",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Next, we load the dataset and apply the transformations defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=data_transforms)\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=data_transforms)\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=data_transforms)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed6175",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "We'll start with a simple feedforward neural network (NeuralNet) and then switch to a more complex convolutional neural network (CNNNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be03c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12288, 84)\n",
    "        self.fc2 = nn.Linear(84, 50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427984f8",
   "metadata": {},
   "source": [
    "Next, we define a more complex convolutional neural network for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "                                      nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "                                      nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(nn.Dropout(),\n",
    "                                        nn.Linear(256 * 6 * 6, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(),\n",
    "                                        nn.Linear(4096, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(4096, num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b84b94",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "We'll train the model using Adam optimizer and cross-entropy loss. The training loop will run for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dad876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "model = CNNNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "        \n",
    "        training_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "                correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "        \n",
    "        valid_loss /= len(val_loader)\n",
    "        accuracy = num_correct / num_examples\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}/{epochs}, Training Loss: {training_loss:.2f}, Validation Loss: {valid_loss:.2f}, Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "train(model, optimizer, loss_fn, train_data_loader, val_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83965f45",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "After training, the model is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model/simple_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1fcfe",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "We will now load the saved model and use it to make predictions on a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "model = torch.load(\"./model/simple_model\")\n",
    "labels = ['cat', 'fish']\n",
    "img = Image.open(\"pexels-crisdip-35358-128756.jpg\")\n",
    "img = data_transforms(img)\n",
    "img = img.unsqueeze(0)\n",
    "prediction = model(img)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
