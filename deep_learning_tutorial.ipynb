{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03699764",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning from a Software Engineer's Perspective\n",
    "\n",
    "## 1. Introduction\n",
    "In this notebook, we will explore the steps involved in building a deep learning model. Starting with problem identification, we'll go through data preparation, building neural networks, and finally training and evaluating a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c3cad",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Identify the Problem\n",
    "**Objective:** For this project, we will classify images into categories using a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd46d8a",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Data Preparation\n",
    "- **Get the Data:** Load images, which are categorized into folders representing different classes (like cats and fish).\n",
    "- **Validate Data:** Ensure that each image is correctly formatted and not corrupted.\n",
    "- **Transform Data:** We resize and normalize images to make them suitable for neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dee624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def validate_images(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            try:\n",
    "                img = Image.open(os.path.join(root, file))\n",
    "                img.verify()  # Check if it's a valid image\n",
    "            except (IOError, UnidentifiedImageError):\n",
    "                print(f\"Removing corrupted image: {file}\")\n",
    "                os.remove(os.path.join(root, file))  # Remove the file if it's corrupted\n",
    "\n",
    "# Define the data paths\n",
    "train_data_path = \"./images/train/\"\n",
    "val_data_path = \"./images/val/\"\n",
    "test_data_path = \"./images/test/\"\n",
    "\n",
    "# Run the validation\n",
    "validate_images(train_data_path)\n",
    "validate_images(val_data_path)\n",
    "validate_images(test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0e24c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Neural Network Basics\n",
    "- **Linear vs Nonlinear Layers:** A brief explanation of how neural networks are structured.\n",
    "- **Activation Functions:** Why activation functions are important for introducing non-linearity.\n",
    "- **Weights and Biases:** The parameters that neural networks learn to make accurate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12288, 84)  # Input layer to hidden layer\n",
    "        self.fc2 = nn.Linear(84, 50)     # Hidden layer to hidden layer\n",
    "        self.fc3 = nn.Linear(50, 2)      # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        x = F.relu(self.fc1(x))    # ReLU activation\n",
    "        x = F.relu(self.fc2(x))    \n",
    "        x = self.fc3(x)            # Output (no softmax for CrossEntropyLoss)\n",
    "        return x\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd2827",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Training\n",
    "- **Epoch:** Training in cycles to improve model performance.\n",
    "- **Device:** Using GPU if available, otherwise using CPU.\n",
    "- **Accuracy and Loss:** Monitoring model performance during training.\n",
    "- **Save Model:** Save the trained model for future predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = CNNNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "        \n",
    "        training_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                valid_loss += loss.item()\n",
    "                correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "        \n",
    "        valid_loss /= len(val_loader)\n",
    "        print(f'Epoch: {epoch + 1}/{epochs}, Training Loss: {training_loss:.2f}, Validation Loss: {valid_loss:.2f}, Accuracy: {num_correct / num_examples:.2f}')\n",
    "    torch.save(model, \"./model/simple_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69a802",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Prediction\n",
    "After training, we can use our model to make predictions on new images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = torch.load(\"./model/simple_model\")\n",
    "labels = ['cat', 'fish']\n",
    "img = Image.open(\"pexels-crisdip-35358-128756.jpg\")\n",
    "img = data_transforms(img)\n",
    "img = img.unsqueeze(0)\n",
    "prediction = model(img)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
